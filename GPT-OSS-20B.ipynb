{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ceb8165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import tempfile\n",
    "import re\n",
    "from groq import Groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a425da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIG =====\n",
    "INPUT_FILENAME = r\"C:\\\\llm_runs\\\\outputs\\\\new_option\\\\failed_questions.json\"\n",
    "OUTPUT_FILENAME = r\"C:\\\\llm_runs\\\\outputs\\\\failed_original_questions_gpt_oss20B.json\"\n",
    "#OUTPUT_FILENAME = r\"C:\\\\llm_runs\\\\outputs\\\\original_gpt_oss20B.json\"\n",
    "\n",
    "# Switch model here\n",
    "MODEL = \"openai/gpt-oss-20b\"\n",
    "# MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "SECONDS_BETWEEN_REQUESTS = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2623a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILENAME), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "68fcadfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0f1da911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(filename, data):\n",
    "    dir_name = os.path.dirname(filename) or \".\"\n",
    "    with tempfile.NamedTemporaryFile(\n",
    "        mode=\"w\",\n",
    "        encoding=\"utf-8\",\n",
    "        dir=dir_name,\n",
    "        delete=False\n",
    "    ) as tmp:\n",
    "        json.dump(data, tmp, indent=2, ensure_ascii=False)\n",
    "        tmp_name = tmp.name\n",
    "\n",
    "    os.replace(tmp_name, filename)  # atomic on Windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "98101c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_answer(question, options):\n",
    "    option_block = \"\\n\".join(\n",
    "        f\"{i}. {opt}\" for i, opt in enumerate(options)\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are answering a multiple choice question.\n",
    "Select the MOST appropriate option.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Options:\n",
    "{option_block}\n",
    "\n",
    "Respond with the option number.\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=10000\n",
    "        #max_tokens = 10000   # IMPORTANT for GPT-OSS\n",
    "    )\n",
    "\n",
    "    text = completion.choices[0].message.content or \"\"\n",
    "\n",
    "    # Robust digit extraction (LIKE YOUR FRIEND)\n",
    "    match = re.search(r\"\\b([0-4])\\b\", text)\n",
    "\n",
    "    return int(match.group(1)) if match else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e3fe9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_indexed():\n",
    "    data = load_data(INPUT_FILENAME)\n",
    "\n",
    "    if os.path.exists(OUTPUT_FILENAME):\n",
    "        try:\n",
    "            results = load_data(OUTPUT_FILENAME)\n",
    "        except json.JSONDecodeError:\n",
    "            results = {}\n",
    "    else:\n",
    "        results = {}\n",
    "\n",
    "    for i, q in enumerate(data):\n",
    "        qid = str(q.get(\"id\", i))\n",
    "\n",
    "        if qid in results:\n",
    "            continue\n",
    "\n",
    "        print(f\"Testing ID {qid}\")\n",
    "\n",
    "        answer = get_model_answer(q[\"question\"], q[\"options\"])\n",
    "\n",
    "        results[qid] = {\n",
    "            \"category\": q.get(\"category\"),\n",
    "            \"answer\": answer\n",
    "        }\n",
    "\n",
    "        save_data(OUTPUT_FILENAME, results)\n",
    "        time.sleep(SECONDS_BETWEEN_REQUESTS)\n",
    "\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7f155267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ID 205\n",
      "Testing ID 288\n",
      "Testing ID 323\n",
      "Testing ID 507\n",
      "Testing ID 514\n",
      "Testing ID 1975\n",
      "Testing ID 2000\n",
      "Testing ID 2124\n",
      "Testing ID 2261\n",
      "Testing ID 2979\n",
      "Testing ID 3222\n",
      "Testing ID 3234\n",
      "Testing ID 3514\n",
      "Testing ID 3594\n",
      "Testing ID 3833\n",
      "Testing ID 4571\n",
      "Testing ID 4718\n",
      "Testing ID 4786\n",
      "Testing ID 5532\n",
      "Testing ID 5735\n",
      "Testing ID 6200\n",
      "Testing ID 6316\n",
      "Testing ID 6655\n",
      "Testing ID 7429\n",
      "Testing ID 8351\n",
      "Testing ID 8942\n",
      "Testing ID 8974\n",
      "Testing ID 9144\n",
      "Testing ID 9330\n",
      "Testing ID 9697\n",
      "Testing ID 9745\n",
      "Testing ID 11294\n",
      "Testing ID 11339\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "run_test_indexed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "79a57c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LLama 3.1 8B instruct(excluding -1): 0.8399754751686083\n",
      "Total evaluated: 11417\n",
      "Correct: 9590\n",
      "Invalid (-1): 18\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paths\n",
    "GT_PATH = \"test_answers_en.json\"\n",
    "PRED_PATH = r\"C:\\\\llm_runs\\\\outputs\\\\original_gpt_oss20B.json\"\n",
    "\n",
    "\n",
    "# Load files\n",
    "with open(GT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "with open(PRED_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    pred = json.load(f)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "invalid = 0\n",
    "\n",
    "for qid, gt_entry in gt.items():\n",
    "    if qid not in pred:\n",
    "        continue  # prediction missing\n",
    "\n",
    "    gt_answer = gt_entry[\"answer\"]\n",
    "    pred_answer = pred[qid][\"answer\"]\n",
    "\n",
    "    if pred_answer == -1:\n",
    "        invalid += 1\n",
    "        continue  # exclude from accuracy\n",
    "\n",
    "    total += 1\n",
    "    if pred_answer == gt_answer:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "\n",
    "print(\"Accuracy of LLama 3.1 8B instruct(excluding -1):\", accuracy)\n",
    "print(\"Total evaluated:\", total)\n",
    "print(\"Correct:\", correct)\n",
    "print(\"Invalid (-1):\", invalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "08437f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_FILENAME, \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "failed_ids = [\n",
    "    qid for qid, entry in results.items()\n",
    "    if entry[\"answer\"] == -1\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "75b7c096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failed (-1) answers: 19\n"
     ]
    }
   ],
   "source": [
    "num_failed = len(failed_ids)\n",
    "\n",
    "print(\"Number of failed (-1) answers:\", num_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e3ab9bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed question IDs:\n",
      "['205', '288', '507', '1975', '2124', '2261', '2979', '3234', '3514', '3833', '5532', '5735', '6655', '8942', '8974', '9144', '9697', '11294', '11339']\n"
     ]
    }
   ],
   "source": [
    "print(\"Failed question IDs:\")\n",
    "print(failed_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7e43a5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failed IDs: 33\n",
      "Failed questions saved to: C:\\llm_runs\\outputs\\new_option\\failed_questions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paths\n",
    "INPUT_FILENAME = \"test_en_reordered.json\"   # original questions\n",
    "OUTPUT_FILENAME = r\"C:\\\\llm_runs\\\\outputs\\\\original_gpt_oss20B.json\"\n",
    "FAILED_QUESTIONS_FILE = r\"C:\\llm_runs\\outputs\\new_option\\failed_questions.json\"\n",
    "\n",
    "# Load data\n",
    "with open(INPUT_FILENAME, \"r\", encoding=\"utf-8\") as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "with open(OUTPUT_FILENAME, \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Collect failed IDs\n",
    "failed_ids = {\n",
    "    qid for qid, entry in results.items()\n",
    "    if entry.get(\"answer\") == -1\n",
    "}\n",
    "\n",
    "print(\"Number of failed IDs:\", len(failed_ids))\n",
    "\n",
    "# Extract failed question objects\n",
    "failed_questions = [\n",
    "    q for q in questions\n",
    "    if str(q.get(\"id\")) in failed_ids\n",
    "]\n",
    "\n",
    "# Save failed questions\n",
    "with open(FAILED_QUESTIONS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(failed_questions, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Failed questions saved to:\", FAILED_QUESTIONS_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
