{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6ee89b",
   "metadata": {},
   "source": [
    "## Testing on the Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66462cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from groq import Groq\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILENAME = \"first_-1.json\"     # your input file\n",
    "OUTPUT_FILENAME = \"first_-1_output.json\" # model outputs\n",
    "\n",
    "MODEL = \"llama-3.1-8b-instant\"\n",
    "SECONDS_BETWEEN_REQUESTS = 1\n",
    "\n",
    "client = Groq(api_key=\"YOUR_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f3e38db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILENAME), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "237dff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_data(filename, data):\n",
    "    dir_name = os.path.dirname(filename) or \".\"\n",
    "    with tempfile.NamedTemporaryFile(\n",
    "        mode=\"w\",\n",
    "        encoding=\"utf-8\",\n",
    "        dir=dir_name,\n",
    "        delete=False\n",
    "    ) as tmp:\n",
    "        json.dump(data, tmp, indent=2, ensure_ascii=False)\n",
    "        tmp_name = tmp.name\n",
    "\n",
    "    os.replace(tmp_name, filename)  # atomic on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9186b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_data(filename, data):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ba2bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_answer(question, options, qid=None):\n",
    "    prompt = f\"\"\"\n",
    "Choose the single most correct answer from the options below.\n",
    "Respond with ONLY the option text, nothing else.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Options:\n",
    "\"\"\" + \"\\n\".join(f\"- {opt}\" for opt in options)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers multiple-choice questions.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=50,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5526865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_indexed():\n",
    "    data = load_data(INPUT_FILENAME)\n",
    "    results = {}  # <-- dict output\n",
    "\n",
    "    for i, q in enumerate(data):\n",
    "        qid = str(q.get(\"id\", i))   # JSON-safe key\n",
    "        category = q.get(\"category\")\n",
    "        question = q[\"question\"]\n",
    "        options = q[\"options\"]\n",
    "\n",
    "        print(f\"\\nTesting ID {qid}\")\n",
    "\n",
    "        try:\n",
    "            model_answer_text = get_model_answer(question, options, qid)\n",
    "\n",
    "            if model_answer_text in options:\n",
    "                answer_index = options.index(model_answer_text)\n",
    "            else:\n",
    "                print(f\"⚠️ Answer not found in options for ID {qid}\")\n",
    "                answer_index = -1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error at ID {qid}: {e}\")\n",
    "            answer_index = -1\n",
    "\n",
    "        results[qid] = {\n",
    "            \"category\": category,\n",
    "            \"answer\": answer_index\n",
    "        }\n",
    "\n",
    "        # Save after every question (safe)\n",
    "        save_data(OUTPUT_FILENAME, results)\n",
    "        time.sleep(SECONDS_BETWEEN_REQUESTS)\n",
    "\n",
    "    print(f\"\\n Done! Saved indexed answers to {OUTPUT_FILENAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a27b7c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ID 7718\n",
      "\n",
      "Testing ID 7719\n",
      "\n",
      "Testing ID 7720\n",
      "\n",
      "Testing ID 7721\n",
      "\n",
      "Testing ID 7722\n",
      "⚠️ Answer not found in options for ID 7722\n",
      "\n",
      "Testing ID 7723\n",
      "\n",
      "Testing ID 7724\n",
      "\n",
      "Testing ID 7725\n",
      "\n",
      "Testing ID 7726\n",
      "\n",
      "Testing ID 7727\n",
      "\n",
      "Testing ID 7728\n",
      "\n",
      "Testing ID 7729\n",
      "⚠️ Answer not found in options for ID 7729\n",
      "\n",
      "Testing ID 7730\n",
      "\n",
      "Testing ID 7731\n",
      "⚠️ Answer not found in options for ID 7731\n",
      "\n",
      "Testing ID 7732\n",
      "\n",
      "Testing ID 7733\n",
      "⚠️ Answer not found in options for ID 7733\n",
      "\n",
      "Testing ID 7734\n",
      "\n",
      "Testing ID 7735\n",
      "\n",
      "Testing ID 7736\n",
      "⚠️ Answer not found in options for ID 7736\n",
      "\n",
      "Testing ID 7737\n",
      "\n",
      "Testing ID 7738\n",
      "\n",
      "Testing ID 7739\n",
      "⚠️ Answer not found in options for ID 7739\n",
      "\n",
      "Testing ID 7740\n",
      "\n",
      "Testing ID 7741\n",
      "\n",
      "Testing ID 7742\n",
      "\n",
      "Testing ID 7743\n",
      "⚠️ Answer not found in options for ID 7743\n",
      "\n",
      "Testing ID 7744\n",
      "\n",
      "Testing ID 7745\n",
      "⚠️ Answer not found in options for ID 7745\n",
      "\n",
      "Testing ID 7746\n",
      "\n",
      "Testing ID 9382\n",
      "⚠️ Answer not found in options for ID 9382\n",
      "\n",
      "Testing ID 9383\n",
      "\n",
      "Testing ID 9384\n",
      "\n",
      "Testing ID 9385\n",
      "\n",
      "Testing ID 9386\n",
      "\n",
      "Testing ID 9387\n",
      "\n",
      "Testing ID 9388\n",
      "⚠️ Answer not found in options for ID 9388\n",
      "\n",
      "Testing ID 9389\n",
      "\n",
      "Testing ID 9390\n",
      "⚠️ Answer not found in options for ID 9390\n",
      "\n",
      "Testing ID 9391\n",
      "\n",
      "Testing ID 9392\n",
      "\n",
      "Testing ID 9393\n",
      "⚠️ Answer not found in options for ID 9393\n",
      "\n",
      "Testing ID 9394\n",
      "\n",
      " Done! Saved indexed answers to first_-1_output.json\n"
     ]
    }
   ],
   "source": [
    "run_test_indexed()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
